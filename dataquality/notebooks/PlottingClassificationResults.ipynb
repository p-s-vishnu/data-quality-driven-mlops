{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiments we split up the code execution to achieve maximum parallelization. This resulted in seperate result json files (included in this repo) which are quickly merged in this notebook. If you re-run the experiments on a single node, you will end up with a single classification_results.json, which you can load manually instead of all the separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "from os.path import dirname\n",
    "import sys\n",
    "sys.path.insert(0, dirname(getcwd()))\n",
    "from json import loads\n",
    "from classification.preprocessing import results_json_to_dataframe, separate_representation_results, get_baselines\n",
    "from classification.plotting import plot_performances\n",
    "from pandas import concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = \"../classification/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"classification_results_class_balance_no_svm.json\", 'r') as file:\n",
    "    class_balance_raw = loads(file.read())\n",
    "df_class_balance = results_json_to_dataframe(class_balance_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"classification_results_completeness_no_svm.json\", 'r') as file:\n",
    "    completeness_raw = loads(file.read())\n",
    "df_completeness = results_json_to_dataframe(completeness_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH+ \"classification_results_consistent_representation_no_svm.json\", 'r') as file:\n",
    "    cons_repr_raw = loads(file.read())\n",
    "df_consistent_representation = results_json_to_dataframe(cons_repr_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"classification_results_target_accuracy_no_svm.json\", 'r') as file:\n",
    "    target_accuracy_raw = loads(file.read())\n",
    "df_target_accuracy = results_json_to_dataframe(target_accuracy_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"classification_results_feature_accuracy_no_svm.json\", 'r') as file:\n",
    "    feature_accuracy_raw = loads(file.read())\n",
    "df_feature_accuracy = results_json_to_dataframe(feature_accuracy_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"classification_results_uniqueness_no_svm.json\", 'r') as file:\n",
    "    uniqueness_raw = loads(file.read())\n",
    "df_uniqueness = results_json_to_dataframe(uniqueness_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RESULTS_PATH + \"classification_results_svm.json\", 'r') as file:\n",
    "    svm_raw = loads(file.read())\n",
    "df_svm = results_json_to_dataframe(svm_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = concat([df_consistent_representation, df_feature_accuracy, df_class_balance, df_completeness, df_target_accuracy, df_uniqueness, df_svm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "baselines = get_baselines()\n",
    "scenarios = ['train_clean_test_clean', 'train_polluted_test_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TelcoCustomerChurn.csv'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ConsistentRepresentationPolluter_five',\n",
       "       'ConsistentRepresentationPolluter_two',\n",
       "       'ConsistentRepresentationPolluter', 'FeatureAccuracyPolluter',\n",
       "       'ClassBalancePolluter', 'CompletenessPolluter',\n",
       "       'TargetAccuracyPolluter', 'UniquenessPolluter_normal',\n",
       "       'UniquenessPolluter_uniform'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polluter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLLUTER = ['CompletenessPolluter', 'FeatureAccuracyPolluter', 'TargetAccuracyPolluter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TelcoCustomerChurn.csv': {'accuracy': {'baseline_majority': 0.7342150170648464,\n",
       "   'baseline_ratio': 0.6167519908987485},\n",
       "  'f1-score': {'baseline_majority': 0.42337023370233706,\n",
       "   'baseline_ratio': 0.5057075307637805}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/psvee/miniforge3/envs/dataquality/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/Users/psvee/miniforge3/envs/dataquality/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/Users/psvee/miniforge3/envs/dataquality/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/Users/psvee/miniforge3/envs/dataquality/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "for polluter in POLLUTER:\n",
    "    if polluter == 'ConsistentRepresentationPolluter':\n",
    "        continue\n",
    "    for dataset in ['TelcoCustomerChurn.csv']:\n",
    "        for scenario in scenarios:\n",
    "            save_path = f\"../figures/{polluter}/{dataset.replace('.csv','')}_{scenario}\"\n",
    "            plot_performances(df, dataset, polluter, scenario, baselines, save_path=f\"{save_path}_accuracy.png\")\n",
    "            plot_performances(df, dataset, polluter, scenario, baselines, use_f1=True, save_path=f\"{save_path}_f1-score.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
